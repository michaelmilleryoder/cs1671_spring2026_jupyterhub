{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca1a81b-d232-4673-b132-b75fb8f6d1fb",
   "metadata": {},
   "source": [
    "# Import necessary packages\n",
    "Test out the environment to make sure you have the packages needed to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca54de36-d46d-405c-9484-06638e22d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test importing package/s.ðŸ¤ž for no errors!\n",
    "import pandas\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f5ed9-ca44-405d-bfe8-b298e3d341ca",
   "metadata": {},
   "source": [
    "# Load Airbnb data\n",
    "We will be using the same Airbnb listing data from a previous session. Check the Files sidebar on the left of JupyterLab to see if you still have that data available. \n",
    "\n",
    "If so, simply <span style=\"color:red\">fill in the name of the CSV file with the listings below</span>. If not, open and run **session3_pandas.ipynb** to download Airbnb listings from a city of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ae933-f2dd-4428-b742-4da9d8615c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "listings_filename = '' # FILL IN the file name for the listings data, with the csv file extension\n",
    "listings = pd.read_csv(listings_filename) # reads CSV file into a pandas dataframe\n",
    "listings.info() # provide basic information about this dataframe\n",
    "listings.head() # see first 5 rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293743a-ffbe-4c05-a426-336922c36290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand pandas view (good for seeing more of text)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "listings[['description']].head() # Look at the description text column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9658d329-3795-409b-90c9-393d4e2d8697",
   "metadata": {},
   "source": [
    "# Cleaning with regular expressions\n",
    "We'll be preprocessing the **description** column to get the text in a nice format for text analysis. First, we'll remove any extraneous text with regular expression pattern matching.\n",
    "We will use [pandas' built-in functions for processing strings](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html#string-methods) to do this. These functions apply to the string transformation to each element in a column.\n",
    "\n",
    "<span style=\"color:red\">Fill in a regular expression to match text that should be removed or replaced below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd6231-04ef-4730-a13a-b8303ff7d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_to_replace = r'' # FILL IN regular expression here\n",
    "replace_with = ' ' # potentially fill in with what you want it to be replaced with\n",
    "\n",
    "listings['description_processed'] = listings['description'].str.replace(pattern_to_replace, replace_with, regex=True)\n",
    "listings[['description', 'description_processed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91726cc3-f784-4298-9ee0-52a39d2e2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NaN values to empty strings\n",
    "listings['description_processed'] = listings['description_processed'].fillna('')\n",
    "listings[['description', 'description_processed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2975e7-0a5b-44fe-ba78-f5b017036224",
   "metadata": {},
   "source": [
    "# Prepare to remove stopwords and punctuation\n",
    "Stopwords are common \"function words\" that serve to connect other words and don't provide much new information. Examples are \"to\", \"and\", and \"of\".\n",
    "\n",
    "We will start with a list from the `nltk` (Natural Language Toolkit) package and add punctuation, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb423482-3c4a-4799-beed-88683502e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') # only need to do once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d0e94-f711-4ed3-a2d5-07181ace7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('english')\n",
    "print(f'NLTK stopwords: {stops}')\n",
    "print(len(stops))\n",
    "print()\n",
    "\n",
    "punctuation = list(string.punctuation)\n",
    "print(punctuation)\n",
    "print()\n",
    "\n",
    "stops += punctuation\n",
    "len(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b15583-e75b-4f74-9d38-6198aef82044",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Tokenization is the process of breaking text up into words! Here we will use the `nltk` package to tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06400aca-37a6-4649-a5f9-d647b0ed6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need to do once\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9f171-e85f-4332-9c7b-1195efc2f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress bar since it could take awhile\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Apply tokenizer from nltk to column\n",
    "# Also remove any tokens that are stopwords\n",
    "def tokenize(text):\n",
    "    tokens_list = nltk.word_tokenize(text)\n",
    "    tokens_list_no_stops = [tok for tok in tokens_list if not tok in stops]\n",
    "    return ' '.join(tokens_list_no_stops)\n",
    "    \n",
    "listings['description_processed'] = listings['description_processed'].progress_map(tokenize)\n",
    "listings[['description', 'description_processed']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
