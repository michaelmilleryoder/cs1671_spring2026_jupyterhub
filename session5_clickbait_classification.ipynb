{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3dc1cc6-10e3-43e0-9b2a-9c3ab64ca08d",
   "metadata": {},
   "source": [
    "# Clickbait classification\n",
    "This notebook guides you through creating a simple machine learning model to classify clickbait from a **training set** of examples of clickbait and not clickbait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec57fcf-c071-4ede-92d4-4976657402fb",
   "metadata": {},
   "source": [
    "# Import necessary packages\n",
    "Test out the environment to make sure you have the packages needed to run this notebook. We'll import **scikit-learn** (sklearn), a useful Python package for traditional machine learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07820ca-d6f9-4299-a43f-34640a6ffb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test importing package/s.ðŸ¤ž for no errors!\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc00fe5-945f-4d1a-8089-8fbd3e945426",
   "metadata": {},
   "source": [
    "## Load clickbait data from Kaggle\n",
    "This data consists of headlines classified as clickbait or not (regular news). It is from a dataset on Kaggle, a site that hosts machine learning datasets and competitions. Source site: https://www.kaggle.com/datasets/amananandrai/clickbait-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90300de0-f52f-4122-a9bf-551271e1ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset with pandas\n",
    "# 0 corresponds to not clickbait, 1 has been judged as clickbait\n",
    "\n",
    "pd.set_option('display.max_colwidth', None) # Make sure entire headlines will be displayed\n",
    "\n",
    "data = pd.read_csv('data/clickbait_data.csv')\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e8cc3e-5f01-448c-ad24-4522945d4f8a",
   "metadata": {},
   "source": [
    "## Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adbeff-1ebf-47b4-a88a-3711794e9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = int(0.1 * len(data))\n",
    "train, test  = train_test_split(data, test_size=test_size)\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f718014-9628-4241-b65a-98711506af11",
   "metadata": {},
   "source": [
    "**What does this \"length\" refer to?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d809d550-dfb8-4182-b288-ae65e56de1d6",
   "metadata": {},
   "source": [
    "## Extract numeric \"features\" from the raw text data\n",
    "This step converts each instance (datapoint, row) of raw text to a numeric vector. No need to worry about the details of this now! We will cover this in the next few class sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f76f8e-26ca-48b4-9a76-21f728f99a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1, tokenizer=nltk.word_tokenize)\n",
    "vectorizer.fit(train['headline']) # input is a list of strings (documents)\n",
    "train_features = vectorizer.transform(train['headline'])\n",
    "test_features = vectorizer.transform(test['headline'])\n",
    "\n",
    "print(type(train_features))\n",
    "print(train_features.shape) # prints (number of rows in the matrix, number of columns)\n",
    "print(test_features.shape)  # prints (number of rows in the matrix, number of columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc38c76-77ef-4ee3-8e50-eb89176773b1",
   "metadata": {},
   "source": [
    "Note that the input is now a **matrix** with each row as a datapoint (headline) and each column as a numeric feature (don't worry about that now). This is one of the places matrices are used in NLP: as input to machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00177f-803f-48f5-9e8b-7d3868824978",
   "metadata": {},
   "source": [
    "## Train Naive Bayes model\n",
    "Naive Bayes is a simple machine learning algorithm that we won't be covering in the course. But you know that as a machine learning model, it learns patterns from a training set, that is, parameters describing relationships between input and output in a mathematical model.\n",
    "\n",
    "That trained model can then be used to make predictions.\n",
    "\n",
    "In our dataset, `train['clickbait']` is the column that contains the **output** we care about: whether the text is clickbait or not. We pass the example input and output in our training set to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198ab49-a0da-4f44-a241-6acbe9888a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_features, train['clickbait'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d39fe-5de3-4741-bd96-99148e79e910",
   "metadata": {},
   "source": [
    "## Make predictions from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d939c9-1eb7-4ac5-a3dc-d2575bd2d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an example from the test set\n",
    "# Note that the classifier has never seen this example\n",
    "\n",
    "example = test.sample(1)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b72de-4b9e-4c74-8843-99ca65daa1eb",
   "metadata": {},
   "source": [
    "Get the text into a vector format that the classifier can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f6790-5378-4564-afac-3162bef5b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_features = vectorizer.transform(example['headline'])\n",
    "example_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6f67c-fb44-4a58-a7d2-5e6bcaad9808",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(example_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aab82e-fc87-4602-8f00-9bc48f50cbff",
   "metadata": {},
   "source": [
    "Recall that 0 = not clickbait and 1 = clickbait. **Did the model get it right?** Feel free to re-run the code in this section with other examples. \n",
    "\n",
    "Evaluation is an important part of machine learning and NLP. We'll systematically evaluate the model on a test set in later class sessions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
